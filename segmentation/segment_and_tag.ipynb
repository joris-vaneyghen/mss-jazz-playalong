{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPv5gS70E+yEvnGWPn2fHO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joris-vaneyghen/mss-jazz-playalong/blob/main/segmentation/segment_and_tag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUlJ7zHjoOvV"
      },
      "outputs": [],
      "source": [
        "!pip install ruptures -q\n",
        "# download our audio example\n",
        "!git clone https://github.com/joris-vaneyghen/mss-jazz-playalong.git\n",
        "# dowload our audio tagger\n",
        "!git clone https://github.com/fschmid56/EfficientAT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd EfficientAT/"
      ],
      "metadata": {
        "id": "UJujlcZNowdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from models.dymn.model import get_model as get_dymn\n",
        "from models.preprocess import AugmentMelSTFT\n",
        "from helpers.utils import NAME_TO_WIDTH\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch import autocast\n",
        "from contextlib import nullcontext\n",
        "import ruptures as rpt\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "0TYrq-D3o0Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = '../mss-jazz-playalong/examples'\n",
        "output_path = '../mss-jazz-playalong/out/demucs'\n",
        "resolution = 0.32 # resolution of EfficientAT model\n",
        "min_size = 8 # De minimale lengte van een segment = 8 chunks  (= 2,56 seconden x 0.32)\n",
        "sample_rate = 32000\n",
        "max_size = 1024 # nb chunks to tag at ones\n"
      ],
      "metadata": {
        "id": "DTAKGUi1pRU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mel_and_dymn20_as(device):\n",
        "    \"\"\"\n",
        "    Load the model and mel spectrogram processor for audio tagging.\n",
        "\n",
        "    Args:\n",
        "        device (torch.device): The device to load the model onto (e.g., 'cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        mel (AugmentMelSTFT): Mel spectrogram processor.\n",
        "        model (torch.nn.Module): Loaded model.\n",
        "    \"\"\"\n",
        "    sample_rate=32000\n",
        "    window_size=800\n",
        "    hop_size=320\n",
        "    n_mels=128\n",
        "    strides=[2, 2, 2, 2]\n",
        "    model_name = 'dymn20_as'\n",
        "\n",
        "    model = get_dymn(width_mult=NAME_TO_WIDTH(model_name), pretrained_name=model_name, strides=strides)\n",
        "\n",
        "    # Send model to the specified device\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Create a mel spectrogram processor (preprocessor)\n",
        "    mel = AugmentMelSTFT(n_mels=n_mels, sr=sample_rate, win_length=window_size, hopsize=hop_size)\n",
        "    mel.to(device)\n",
        "    mel.eval()\n",
        "\n",
        "    return mel, model\n",
        "\n",
        "def preds_over_time(mel, model, waveform, device):\n",
        "  waveform = torch.from_numpy(waveform).to(device)  # shape = (C=2, L)\n",
        "  all_preds = []\n",
        "  all_embeds = []\n",
        "  all_features = []\n",
        "\n",
        "  max_input_length = int(max_size * sample_rate * resolution)\n",
        "\n",
        "  # Process waveform in segments of max_input_length\n",
        "  num_samples = waveform.shape[1]\n",
        "  for start_idx in range(0, num_samples, max_input_length):\n",
        "      end_idx = min(start_idx + max_input_length, num_samples)\n",
        "      waveform_segment = waveform[:, start_idx:end_idx]  # Segment of the waveform\n",
        "\n",
        "      with torch.no_grad(), autocast(device_type=device) if device == 'cuda' else nullcontext():\n",
        "          # Compute mel-spectrogram for the current segment\n",
        "          spec = mel(waveform_segment)  # shape = (C, F=128, T=(end_idx - start_idx) / 320)\n",
        "          input = spec.unsqueeze(1)  # shape = (N=C, D=1, F, T)\n",
        "          features = model._feature_forward(input)  # shape = (N, D=1920, F'=F/32, T'â‰ƒT/32)\n",
        "\n",
        "          # Permute Time with Batch dimensions so that avg pooling is done on the batch and frequency dimension\n",
        "          features = features.permute(3, 1, 2, 0)  # shape = (T', F', C', N)\n",
        "          preds, embed = model._clf_forward(features)\n",
        "          preds = torch.sigmoid(preds.float()).squeeze().cpu().numpy()  # shape = (T', D'=527)\n",
        "\n",
        "          # Collect predictions, embeddings, and features\n",
        "          all_preds.append(preds)\n",
        "          all_embeds.append(embed.cpu().numpy())\n",
        "          all_features.append(features.cpu().numpy())\n",
        "\n",
        "  # Concatenate the results from all segments\n",
        "  all_preds = np.concatenate(all_preds, axis=0)  # Concatenate over time axis\n",
        "  all_embeds = np.concatenate(all_embeds, axis=0)  # Concatenate embeddings over time axis\n",
        "  all_features = np.concatenate(all_features, axis=0)  # Concatenate features over time axis\n",
        "\n",
        "  return all_preds, all_embeds, all_features\n",
        "\n",
        "\n",
        "\n",
        "def features_to_preds(model, features, device):\n",
        "  features = torch.from_numpy(features).to(device)\n",
        "  features = features.permute(3, 1, 2, 0)\n",
        "  features = torch.mean(features, dim=0, keepdim=True)\n",
        "  with torch.no_grad(), autocast(device_type=device) if device == 'cuda' else nullcontext():\n",
        "    preds, embed = model._clf_forward(features)\n",
        "    preds = torch.sigmoid(preds.float()).squeeze().cpu().numpy() # shape = (T', D'=527)\n",
        "  return preds, embed.squeeze().cpu().numpy()\n",
        "\n",
        "def load_json(dir, mp3_file):\n",
        "    # Replace .mp3 extension with .json\n",
        "    json_file_name = mp3_file.replace('.mp3', '.json')\n",
        "    file_path = os.path.join(dir, json_file_name)\n",
        "\n",
        "    # Check if the .json file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        return {}  # Return an empty dictionary if the .json file doesn't exist\n",
        "\n",
        "    # Load the JSON file if it exists\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "def save_json(dir, mp3_file, data):\n",
        "    # Replace .mp3 extension with .json\n",
        "    json_file_name = mp3_file.replace('.mp3', '.json')\n",
        "    file_path = os.path.join(dir, json_file_name)\n",
        "\n",
        "    # Check if directory exists, create it if not\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    # Save the data to the .json file\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "def iterate_files(dir):\n",
        "    for file_name in os.listdir(dir):\n",
        "        if file_name.endswith('.mp3'):\n",
        "            yield file_name\n",
        "\n",
        "def calculate_bkpts_from_demucs(demucs):\n",
        "  drums = np.array(demucs['drums'])\n",
        "  bass = np.array(demucs['bass'])\n",
        "  vocals = np.array(demucs['vocals'])\n",
        "  other = np.array(demucs['other'])\n",
        "  stacked_signal = np.stack((drums, bass, vocals, other), axis=1)\n",
        "\n",
        "  # Gebruik de Pelt-methode voor breekpuntdetectie\n",
        "  model = \"normal\"\n",
        "  algo = rpt.Pelt(model=model, min_size=min_size, jump=1).fit(stacked_signal)\n",
        "\n",
        "  # Detecteer breekpunten, zonder het aantal vooraf te specificeren\n",
        "  penalty = 100  # Penalty bepaalt hoe streng we breekpunten toestaan, je kunt hiermee spelen\n",
        "  bkps = algo.predict(pen=penalty)\n",
        "\n",
        "  return bkps\n",
        "\n",
        "\n",
        "def calculate_bpts_from_tagger(preds, bkps_demucs):\n",
        "  pca = PCA(n_components=20)  # Reduce to 20 dimensions\n",
        "  reduced_data = pca.fit_transform(preds)\n",
        "\n",
        "  start = 0\n",
        "  new_bkps = []\n",
        "  for i in range(len(bkps_demucs)):\n",
        "    end = bkps_demucs[i]\n",
        "    signal = reduced_data[start:end]\n",
        "\n",
        "    # Gebruik de Pelt-methode voor breekpuntdetectie\n",
        "    model = \"rbf\"\n",
        "    algo = rpt.Pelt(model=model, min_size=min_size, jump=1).fit(signal)\n",
        "    # Detecteer breekpunten, zonder het aantal vooraf te specificeren\n",
        "    penalty = 3  # Penalty bepaalt hoe streng we breekpunten toestaan, je kunt hiermee spelen\n",
        "    sub_bkps = algo.predict(pen=penalty)\n",
        "    new_bkps.extend([bkp + start for bkp in sub_bkps])\n",
        "    start  = end\n",
        "\n",
        "  return new_bkps\n",
        "\n",
        "\n",
        "def avg_preds_per_segemnt(model, bkps, features, demucs):\n",
        "  start = 0\n",
        "  segments = []\n",
        "  for i in range(len(bkps)):\n",
        "    end = bkps[i]\n",
        "    preds_i, embed_i = features_to_preds(model, features[start: end], device);\n",
        "    segment = {}\n",
        "    segment['start_idx'] = start\n",
        "    segment['end_idx'] = end\n",
        "    segment['preds'] = preds_i.tolist()\n",
        "    # segment['embed'] = embed_i.tolist()\n",
        "    for key in demucs.keys():\n",
        "      segment[key] = np.array(demucs[key][start:end]).mean(axis=0)\n",
        "    segments.append(segment)\n",
        "    start = end\n",
        "\n",
        "  return segments\n",
        "\n"
      ],
      "metadata": {
        "id": "GvQlUQpNo2Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "mel, model = load_mel_and_dymn20_as(device)\n",
        "\n",
        "\n",
        "for mp3_file in iterate_files(input_path):\n",
        "  data = load_json(output_path, mp3_file)\n",
        "  if ('demucs' in data.keys() and 'segments' not in data.keys()):\n",
        "    print(mp3_file)\n",
        "    audio_path = os.path.join(input_path, mp3_file)\n",
        "    (waveform, _) = librosa.core.load(audio_path, sr=32000, mono=False)\n",
        "    bkpts_demucs = calculate_bkpts_from_demucs(data['demucs'])\n",
        "    preds, embed, features = preds_over_time(mel, model, waveform, device)\n",
        "    bkpts_tagger = calculate_bpts_from_tagger(preds, bkpts_demucs)\n",
        "    segments = avg_preds_per_segemnt(model, bkpts_tagger, features, data['demucs'])\n",
        "    data['segments'] = segments\n",
        "\n",
        "    save_json(output_path, mp3_file, data)"
      ],
      "metadata": {
        "id": "qnD8FJzup121"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}